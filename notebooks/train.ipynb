{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c6bd0f-bac1-4640-b670-8166a69da32d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823993c-d308-4f1e-a912-185b86f65265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln, logsumexp\n",
    "from typing import Union, NoReturn, Tuple, List\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dcdc3-9124-47c2-8aba-93b75234dfc8",
   "metadata": {},
   "source": [
    "# Load artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77cc2dfd-8fd0-45e3-960b-4056dce93c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input: str = 'outputs/preprocess'\n",
    "x_wordtype_counts_left: np.ndarray = joblib.load(f'{path_input}/x_wordtype_counts_left.joblib')\n",
    "x_wordtype_counts_right: np.ndarray = joblib.load(f'{path_input}/x_wordtype_counts_right.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25cc05-f3e3-40a3-8ec1-17006490cc31",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e80f2718-fd8a-4795-8e38-9edcddddb450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 log_prob: -3814957.313596132\n",
      "Iteration: 1 log_prob: -3762832.06326032\n",
      "Iteration: 2 log_prob: -3743432.77095983\n",
      "Iteration: 3 log_prob: -3728856.8830803595\n",
      "Iteration: 4 log_prob: -3718779.4756111894\n",
      "Iteration: 5 log_prob: -3710747.0204397202\n",
      "Iteration: 6 log_prob: -3703264.566998626\n",
      "Iteration: 7 log_prob: -3697854.3233359554\n",
      "Iteration: 8 log_prob: -3693612.5714386534\n",
      "Iteration: 9 log_prob: -3687255.8488912676\n",
      "Iteration: 10 log_prob: -3682529.79133762\n",
      "Iteration: 11 log_prob: -3676529.871481222\n",
      "Iteration: 12 log_prob: -3673015.3742763083\n",
      "Iteration: 13 log_prob: -3669099.069491315\n",
      "Iteration: 14 log_prob: -3666769.7009779466\n",
      "Iteration: 15 log_prob: -3664064.198443897\n",
      "Iteration: 16 log_prob: -3662377.07798611\n",
      "Iteration: 17 log_prob: -3659839.262822422\n",
      "Iteration: 18 log_prob: -3659650.869774912\n",
      "Iteration: 19 log_prob: -3658905.4467309695\n",
      "Iteration: 20 log_prob: -3657425.343667348\n",
      "Iteration: 21 log_prob: -3656502.235012497\n",
      "Iteration: 22 log_prob: -3656261.7615850763\n",
      "Iteration: 23 log_prob: -3655417.260257577\n",
      "Iteration: 24 log_prob: -3656246.0340597164\n",
      "Iteration: 25 log_prob: -3655542.5713338666\n",
      "Iteration: 26 log_prob: -3656008.225708635\n",
      "Iteration: 27 log_prob: -3655930.7946656393\n",
      "Iteration: 28 log_prob: -3655990.924615927\n",
      "Iteration: 29 log_prob: -3656100.195758936\n",
      "Iteration: 30 log_prob: -3657229.21017386\n",
      "Iteration: 31 log_prob: -3656422.7838976504\n",
      "Iteration: 32 log_prob: -3655666.027903783\n",
      "Iteration: 33 log_prob: -3656611.417637389\n",
      "Iteration: 34 log_prob: -3656209.4759032354\n",
      "Iteration: 35 log_prob: -3655731.320347175\n",
      "Iteration: 36 log_prob: -3655815.6032143077\n",
      "Iteration: 37 log_prob: -3654529.567612416\n",
      "Iteration: 38 log_prob: -3655193.6872215737\n",
      "Iteration: 39 log_prob: -3656438.879014903\n",
      "Iteration: 40 log_prob: -3656616.698729316\n",
      "Iteration: 41 log_prob: -3656348.324622958\n",
      "Iteration: 42 log_prob: -3656187.44321675\n",
      "Iteration: 43 log_prob: -3655663.5744786733\n",
      "Iteration: 44 log_prob: -3655613.9930526484\n",
      "Iteration: 45 log_prob: -3655685.198374397\n",
      "Iteration: 46 log_prob: -3655940.326727922\n",
      "Iteration: 47 log_prob: -3655027.700954028\n",
      "Iteration: 48 log_prob: -3655131.245531784\n",
      "Iteration: 49 log_prob: -3655496.128081106\n",
      "Iteration: 50 log_prob: -3654832.949602266\n",
      "Iteration: 51 log_prob: -3655771.8378678905\n",
      "Iteration: 52 log_prob: -3655643.5321578803\n",
      "Iteration: 53 log_prob: -3654670.092456634\n",
      "Iteration: 54 log_prob: -3655078.7719046827\n",
      "Iteration: 55 log_prob: -3654501.649719298\n",
      "Iteration: 56 log_prob: -3654754.5321636996\n",
      "Iteration: 57 log_prob: -3655022.3112782\n",
      "Iteration: 58 log_prob: -3655948.4540546834\n",
      "Iteration: 59 log_prob: -3655978.5695950733\n",
      "Iteration: 60 log_prob: -3655511.8444437874\n",
      "Iteration: 61 log_prob: -3655658.736898125\n",
      "Iteration: 62 log_prob: -3656069.6055881744\n",
      "Iteration: 63 log_prob: -3654178.098231525\n",
      "Iteration: 64 log_prob: -3654300.88810175\n",
      "Iteration: 65 log_prob: -3654332.1285961564\n",
      "Iteration: 66 log_prob: -3654001.7893986893\n",
      "Iteration: 67 log_prob: -3655094.035723039\n",
      "Iteration: 68 log_prob: -3654767.661410697\n",
      "Iteration: 69 log_prob: -3655069.8273548065\n",
      "Iteration: 70 log_prob: -3654656.4275019\n",
      "Iteration: 71 log_prob: -3654915.8340842067\n",
      "Iteration: 72 log_prob: -3655528.511260516\n",
      "Iteration: 73 log_prob: -3654977.052517468\n",
      "Iteration: 74 log_prob: -3654468.731957919\n",
      "Iteration: 75 log_prob: -3654039.534513924\n",
      "Iteration: 76 log_prob: -3653444.835070839\n",
      "Iteration: 77 log_prob: -3652916.9391362844\n",
      "Iteration: 78 log_prob: -3653825.6175628346\n",
      "Iteration: 79 log_prob: -3652835.8894534707\n",
      "Iteration: 80 log_prob: -3652465.8193197856\n",
      "Iteration: 81 log_prob: -3652657.7543653958\n",
      "Iteration: 82 log_prob: -3652760.8541927394\n",
      "Iteration: 83 log_prob: -3653717.98901443\n",
      "Iteration: 84 log_prob: -3653815.924611235\n",
      "Iteration: 85 log_prob: -3653615.114356168\n",
      "Iteration: 86 log_prob: -3654224.6652868115\n",
      "Iteration: 87 log_prob: -3653752.395625947\n",
      "Iteration: 88 log_prob: -3654037.8864292456\n",
      "Iteration: 89 log_prob: -3653543.3802630277\n",
      "Iteration: 90 log_prob: -3655022.7612173515\n",
      "Iteration: 91 log_prob: -3654099.355258894\n",
      "Iteration: 92 log_prob: -3653831.510642833\n",
      "Iteration: 93 log_prob: -3653505.237649066\n",
      "Iteration: 94 log_prob: -3654854.8086782824\n",
      "Iteration: 95 log_prob: -3654745.3949211547\n",
      "Iteration: 96 log_prob: -3653734.866115954\n",
      "Iteration: 97 log_prob: -3654226.0298278145\n",
      "Iteration: 98 log_prob: -3654716.445628974\n",
      "Iteration: 99 log_prob: -3654001.0638658884\n",
      "Iteration: 100 log_prob: -3654758.6580388397\n",
      "Iteration: 101 log_prob: -3654216.3751991284\n",
      "Iteration: 102 log_prob: -3655247.4953730498\n",
      "Iteration: 103 log_prob: -3654169.006431664\n",
      "Iteration: 104 log_prob: -3653755.9443335994\n",
      "Iteration: 105 log_prob: -3653457.414198404\n",
      "Iteration: 106 log_prob: -3652952.881788402\n",
      "Iteration: 107 log_prob: -3653403.2422005716\n",
      "Iteration: 108 log_prob: -3653115.0591359036\n",
      "Iteration: 109 log_prob: -3653369.8907407513\n",
      "Iteration: 110 log_prob: -3653953.0994113265\n",
      "Iteration: 111 log_prob: -3653785.7755839475\n",
      "Iteration: 112 log_prob: -3654786.055659662\n",
      "Iteration: 113 log_prob: -3654551.3775677755\n",
      "Iteration: 114 log_prob: -3654339.364107635\n",
      "Iteration: 115 log_prob: -3654579.553809924\n",
      "Iteration: 116 log_prob: -3653903.708195883\n",
      "Iteration: 117 log_prob: -3654135.804605512\n",
      "Iteration: 118 log_prob: -3654054.5972137647\n",
      "Iteration: 119 log_prob: -3653906.0167868985\n",
      "Iteration: 120 log_prob: -3653292.9212896153\n",
      "Iteration: 121 log_prob: -3653324.053570651\n",
      "Iteration: 122 log_prob: -3653495.901456058\n",
      "Iteration: 123 log_prob: -3654143.357899904\n",
      "Iteration: 124 log_prob: -3653355.00038772\n",
      "Iteration: 125 log_prob: -3654014.411535685\n",
      "Iteration: 126 log_prob: -3654222.878218879\n",
      "Iteration: 127 log_prob: -3654142.301307075\n",
      "Iteration: 128 log_prob: -3653791.745857939\n",
      "Iteration: 129 log_prob: -3654191.3452402484\n",
      "Iteration: 130 log_prob: -3653700.2159444424\n",
      "Iteration: 131 log_prob: -3654136.714162863\n",
      "Iteration: 132 log_prob: -3654801.6326191644\n",
      "Iteration: 133 log_prob: -3654551.7096044905\n",
      "Iteration: 134 log_prob: -3654238.038026192\n",
      "Iteration: 135 log_prob: -3654428.4732338116\n",
      "Iteration: 136 log_prob: -3655006.091369823\n",
      "Iteration: 137 log_prob: -3654174.5187594653\n",
      "Iteration: 138 log_prob: -3654720.6379803335\n",
      "Iteration: 139 log_prob: -3653534.3235618346\n",
      "Iteration: 140 log_prob: -3654967.536837865\n",
      "Iteration: 141 log_prob: -3654301.371633839\n",
      "Iteration: 142 log_prob: -3653863.1526637133\n",
      "Iteration: 143 log_prob: -3654226.8914771057\n",
      "Iteration: 144 log_prob: -3654134.4323551967\n",
      "Iteration: 145 log_prob: -3654077.775988153\n",
      "Iteration: 146 log_prob: -3654093.7949963585\n",
      "Iteration: 147 log_prob: -3654445.580517476\n",
      "Iteration: 148 log_prob: -3654025.643982277\n",
      "Iteration: 149 log_prob: -3654016.2091722423\n",
      "Iteration: 150 log_prob: -3654865.976415628\n",
      "Iteration: 151 log_prob: -3654959.3136578375\n",
      "Iteration: 152 log_prob: -3654218.941267891\n",
      "Iteration: 153 log_prob: -3654384.714510107\n",
      "Iteration: 154 log_prob: -3653892.9706679196\n",
      "Iteration: 155 log_prob: -3652922.7804635414\n",
      "Iteration: 156 log_prob: -3654081.210056187\n",
      "Iteration: 157 log_prob: -3654098.1021122104\n",
      "Iteration: 158 log_prob: -3653943.960545263\n",
      "Iteration: 159 log_prob: -3654205.7682069833\n",
      "Iteration: 160 log_prob: -3654287.4384408398\n",
      "Iteration: 161 log_prob: -3653873.3930648426\n",
      "Iteration: 162 log_prob: -3653371.9967351705\n",
      "Iteration: 163 log_prob: -3653067.433032413\n",
      "Iteration: 164 log_prob: -3652713.2102128416\n",
      "Iteration: 165 log_prob: -3652973.2011841172\n",
      "Iteration: 166 log_prob: -3652902.4396294905\n",
      "Iteration: 167 log_prob: -3653021.811194781\n",
      "Iteration: 168 log_prob: -3652380.6880568215\n",
      "Iteration: 169 log_prob: -3652271.394998928\n",
      "Iteration: 170 log_prob: -3652159.668708982\n",
      "Iteration: 171 log_prob: -3652602.2002908625\n",
      "Iteration: 172 log_prob: -3652819.244716243\n",
      "Iteration: 173 log_prob: -3654008.9038914377\n",
      "Iteration: 174 log_prob: -3654139.3789904388\n",
      "Iteration: 175 log_prob: -3654100.761216972\n",
      "Iteration: 176 log_prob: -3654049.544703471\n",
      "Iteration: 177 log_prob: -3653808.3236065945\n",
      "Iteration: 178 log_prob: -3654168.101234416\n",
      "Iteration: 179 log_prob: -3653514.4122368144\n",
      "Iteration: 180 log_prob: -3653043.364747128\n",
      "Iteration: 181 log_prob: -3653969.979068579\n",
      "Iteration: 182 log_prob: -3654782.355890975\n",
      "Iteration: 183 log_prob: -3654272.5933921197\n",
      "Iteration: 184 log_prob: -3654787.2404668257\n",
      "Iteration: 185 log_prob: -3654917.5576269506\n",
      "Iteration: 186 log_prob: -3655148.059436208\n",
      "Iteration: 187 log_prob: -3654692.7693199604\n",
      "Iteration: 188 log_prob: -3654607.5078500584\n",
      "Iteration: 189 log_prob: -3655107.78441213\n",
      "Iteration: 190 log_prob: -3655095.2391213956\n",
      "Iteration: 191 log_prob: -3654381.3388808067\n",
      "Iteration: 192 log_prob: -3654429.050998808\n",
      "Iteration: 193 log_prob: -3654264.6975078983\n",
      "Iteration: 194 log_prob: -3654224.919646433\n",
      "Iteration: 195 log_prob: -3654133.007418552\n",
      "Iteration: 196 log_prob: -3653642.562034334\n",
      "Iteration: 197 log_prob: -3653014.549226554\n",
      "Iteration: 198 log_prob: -3654079.1883714744\n",
      "Iteration: 199 log_prob: -3653099.6001743553\n",
      "Iteration: 200 log_prob: -3653552.2491410235\n",
      "Iteration: 201 log_prob: -3653134.271507484\n",
      "Iteration: 202 log_prob: -3653128.7035850054\n",
      "Iteration: 203 log_prob: -3653341.057270237\n",
      "Iteration: 204 log_prob: -3653979.1935871737\n",
      "Iteration: 205 log_prob: -3653224.6858569114\n",
      "Iteration: 206 log_prob: -3653340.6038067304\n",
      "Iteration: 207 log_prob: -3653460.5918767964\n",
      "Iteration: 208 log_prob: -3653759.6356172655\n",
      "Iteration: 209 log_prob: -3653889.9337983024\n",
      "Iteration: 210 log_prob: -3653483.6963024847\n",
      "Iteration: 211 log_prob: -3654279.1496193837\n",
      "Iteration: 212 log_prob: -3654189.9030261207\n",
      "Iteration: 213 log_prob: -3654805.6866838196\n",
      "Iteration: 214 log_prob: -3654294.643391146\n",
      "Iteration: 215 log_prob: -3654914.8271730733\n",
      "Iteration: 216 log_prob: -3654432.814103863\n",
      "Iteration: 217 log_prob: -3654725.790846906\n",
      "Iteration: 218 log_prob: -3655023.6868934194\n",
      "Iteration: 219 log_prob: -3654612.865915129\n",
      "Iteration: 220 log_prob: -3654455.134691298\n",
      "Iteration: 221 log_prob: -3654537.4540471984\n",
      "Iteration: 222 log_prob: -3654307.891982913\n",
      "Iteration: 223 log_prob: -3654156.167391262\n",
      "Iteration: 224 log_prob: -3653517.138539693\n",
      "Iteration: 225 log_prob: -3654007.4167943522\n",
      "Iteration: 226 log_prob: -3655079.8652094947\n",
      "Iteration: 227 log_prob: -3654352.0265573566\n",
      "Iteration: 228 log_prob: -3654445.2431732398\n",
      "Iteration: 229 log_prob: -3654091.975252777\n",
      "Iteration: 230 log_prob: -3654052.6075819833\n",
      "Iteration: 231 log_prob: -3654512.501385654\n",
      "Iteration: 232 log_prob: -3654973.704944516\n",
      "Iteration: 233 log_prob: -3655293.6641756077\n",
      "Iteration: 234 log_prob: -3654192.908926061\n",
      "Iteration: 235 log_prob: -3653863.570807229\n",
      "Iteration: 236 log_prob: -3653931.458894886\n",
      "Iteration: 237 log_prob: -3653030.7046508333\n",
      "Iteration: 238 log_prob: -3653223.9064785177\n",
      "Iteration: 239 log_prob: -3652794.254103317\n",
      "Iteration: 240 log_prob: -3653573.9788266607\n",
      "Iteration: 241 log_prob: -3652793.7064814293\n",
      "Iteration: 242 log_prob: -3653135.0696670376\n",
      "Iteration: 243 log_prob: -3653651.841546402\n",
      "Iteration: 244 log_prob: -3653778.1414563516\n",
      "Iteration: 245 log_prob: -3652843.197879321\n",
      "Iteration: 246 log_prob: -3652629.466123907\n",
      "Iteration: 247 log_prob: -3652876.047881865\n",
      "Iteration: 248 log_prob: -3653403.049853155\n",
      "Iteration: 249 log_prob: -3653670.743504825\n",
      "Iteration: 250 log_prob: -3654067.618662962\n",
      "Iteration: 251 log_prob: -3652727.1402046317\n",
      "Iteration: 252 log_prob: -3653006.9032592257\n",
      "Iteration: 253 log_prob: -3653781.861981401\n",
      "Iteration: 254 log_prob: -3653684.0906412965\n",
      "Iteration: 255 log_prob: -3653427.244541456\n",
      "Iteration: 256 log_prob: -3653626.7686671605\n",
      "Iteration: 257 log_prob: -3654700.342696689\n",
      "Iteration: 258 log_prob: -3653969.7488105567\n",
      "Iteration: 259 log_prob: -3652971.5150932344\n",
      "Iteration: 260 log_prob: -3654002.9367934437\n",
      "Iteration: 261 log_prob: -3653571.8527959576\n",
      "Iteration: 262 log_prob: -3653991.961477156\n",
      "Iteration: 263 log_prob: -3654888.9648445346\n",
      "Iteration: 264 log_prob: -3655396.3357324963\n",
      "Iteration: 265 log_prob: -3654486.6025964697\n",
      "Iteration: 266 log_prob: -3655449.129902057\n",
      "Iteration: 267 log_prob: -3654845.1935674762\n",
      "Iteration: 268 log_prob: -3654078.658391555\n",
      "Iteration: 269 log_prob: -3654020.278385501\n",
      "Iteration: 270 log_prob: -3654668.5172348106\n",
      "Iteration: 271 log_prob: -3653659.027246729\n",
      "Iteration: 272 log_prob: -3653395.7942655925\n",
      "Iteration: 273 log_prob: -3652860.7010688605\n",
      "Iteration: 274 log_prob: -3652390.2819833113\n",
      "Iteration: 275 log_prob: -3652438.7533072922\n",
      "Iteration: 276 log_prob: -3654031.5723036234\n",
      "Iteration: 277 log_prob: -3654163.9389265613\n",
      "Iteration: 278 log_prob: -3653231.442149618\n",
      "Iteration: 279 log_prob: -3653551.3575044055\n",
      "Iteration: 280 log_prob: -3653252.431754298\n",
      "Iteration: 281 log_prob: -3653594.512533594\n",
      "Iteration: 282 log_prob: -3653427.01170713\n",
      "Iteration: 283 log_prob: -3653540.459556532\n",
      "Iteration: 284 log_prob: -3654107.2192805074\n",
      "Iteration: 285 log_prob: -3653255.2051484543\n",
      "Iteration: 286 log_prob: -3653071.9904267504\n",
      "Iteration: 287 log_prob: -3653120.7154099634\n",
      "Iteration: 288 log_prob: -3653611.6078807265\n",
      "Iteration: 289 log_prob: -3652994.382749705\n",
      "Iteration: 290 log_prob: -3653028.6295587737\n",
      "Iteration: 291 log_prob: -3653513.4622885743\n",
      "Iteration: 292 log_prob: -3652873.0556868017\n",
      "Iteration: 293 log_prob: -3652388.7347715786\n",
      "Iteration: 294 log_prob: -3652193.4318172955\n",
      "Iteration: 295 log_prob: -3652495.5163919935\n",
      "Iteration: 296 log_prob: -3653082.0756361336\n",
      "Iteration: 297 log_prob: -3653444.32229169\n",
      "Iteration: 298 log_prob: -3652887.9791787374\n",
      "Iteration: 299 log_prob: -3653824.586071164\n"
     ]
    }
   ],
   "source": [
    "class GibbsSampler:\n",
    "    \"\"\"GibbsSampler.\"\"\"\n",
    "\n",
    "    def __init__(self, x_wordtype_counts_left: np.ndarray, x_wordtype_counts_right: np.ndarray, n_classes: int):\n",
    "        \"\"\"Init.\"\"\"\n",
    "        # validate input params\n",
    "        assert isinstance(x_wordtype_counts_left, np.ndarray)\n",
    "        assert isinstance(x_wordtype_counts_right, np.ndarray)\n",
    "        assert isinstance(n_classes, int)\n",
    "        assert n_classes > 0\n",
    "\n",
    "        self._x_wordtype_counts_left = x_wordtype_counts_left\n",
    "        self._x_wordtype_counts_right = x_wordtype_counts_right\n",
    "        self._n_classes = n_classes\n",
    "\n",
    "        # initialise gibbs structures\n",
    "        self._x_class_priors = np.array([1 / self._n_classes] * self._n_classes) # shape: Z (n_classes,)\n",
    "        self._n_wordtypes, self._n_features = self._x_wordtype_counts_left.shape\n",
    "        self._x_wordtype_class_assignments = np.random.choice(range(len(self._x_class_priors)), p=self._x_class_priors, size=self._n_wordtypes) # shape: M (n_wordtypes,)\n",
    "        self._x_class_counts = np.bincount(self._x_wordtype_class_assignments) # shape: Z (n_classes,)\n",
    "        self._x_class_wordtype_counts_left = np.zeros((n_classes, n_features)).astype(int)\n",
    "        self._x_class_wordtype_counts_right = np.zeros((n_classes, n_features)).astype(int)\n",
    "        np.add.at(self._x_class_wordtype_counts_left, self._x_wordtype_class_assignments, self._x_wordtype_counts_left)\n",
    "        np.add.at(self._x_class_wordtype_counts_right, self._x_wordtype_class_assignments, self._x_wordtype_counts_right)\n",
    "        self._x_class_wordtype_counts_sum_left = self._x_class_wordtype_counts_left.sum(axis=1)\n",
    "        self._x_class_wordtype_counts_sum_right = self._x_class_wordtype_counts_right.sum(axis=1)\n",
    "        self._x_wordtype_counts_sum_left = self._x_wordtype_counts_left.sum(axis=1)  # M (n_wordtypes)\n",
    "        self._x_wordtype_counts_sum_right = self._x_wordtype_counts_right.sum(axis=1)  # M (n_wordtypes)\n",
    "\n",
    "        # validate gibbs structures\n",
    "        _ = self._validate_initialisation()\n",
    "\n",
    "    def _validate_initialisation(self) -> Union[None, NoReturn]:\n",
    "        \"\"\"Validate initialisation structures.\"\"\"\n",
    "        assert self._x_class_priors.shape == (n_classes,)\n",
    "        assert self._x_wordtype_class_assignments.shape == (n_wordtypes,)\n",
    "        assert self._x_class_counts.shape == (n_classes,)\n",
    "        assert self._x_wordtype_class_assignments.shape == (n_wordtypes,)\n",
    "        assert self._x_class_wordtype_counts_left.shape == (self._n_classes, self._n_features)\n",
    "        assert self._x_class_wordtype_counts_right.shape == (self._n_classes, self._n_features)\n",
    "        assert self._x_class_wordtype_counts_sum_left.shape == (self._n_classes,)\n",
    "        assert self._x_class_wordtype_counts_sum_right.shape == (self._n_classes,)\n",
    "        assert self._x_wordtype_counts_sum_left.shape == (n_wordtypes,)\n",
    "        assert self._x_wordtype_counts_sum_right.shape == (n_wordtypes,)\n",
    "    \n",
    "    def _compute_log_conditional_probability(self, ix: int, alpha: float, beta_left: float, beta_right: float) -> np.ndarray:\n",
    "        \"\"\"Compute Gibbs sampling log conditional.\"\"\"\n",
    "        # compute prior\n",
    "        log_probs: float = np.log(self._x_class_counts + alpha) # drop denominator since its common to all classes.\n",
    "\n",
    "        # left context features\n",
    "        log_probs += (\n",
    "            (\n",
    "                gammaln(self._x_class_wordtype_counts_left + self._x_wordtype_counts_left[ix] + beta_left)\n",
    "                - gammaln(self._x_class_wordtype_counts_left + beta_left)\n",
    "            ).sum(axis=1)\n",
    "            - (\n",
    "                gammaln(self._x_class_wordtype_counts_sum_left + self._x_wordtype_counts_sum_left[ix] + self._n_features * beta_left)\n",
    "                - gammaln(self._x_class_wordtype_counts_sum_left + self._n_features * beta_left)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # right context features\n",
    "        log_probs += (\n",
    "            (\n",
    "                gammaln(self._x_class_wordtype_counts_right + self._x_wordtype_counts_right[ix] + beta_right)\n",
    "                - gammaln(self._x_class_wordtype_counts_right + beta_right)\n",
    "            ).sum(axis=1)\n",
    "            - (\n",
    "                gammaln(self._x_class_wordtype_counts_sum_right + self._x_wordtype_counts_sum_right[ix] + self._n_features * beta_right)\n",
    "                - gammaln(self._x_class_wordtype_counts_sum_right + self._n_features * beta_right)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # normalise\n",
    "        log_probs -= logsumexp(log_probs)\n",
    "        \n",
    "        # convert to probs\n",
    "        probs: float = np.exp(log_probs)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def _compute_log_joint_probability(self, alpha: float, beta_left: float, beta_right: float) -> float:\n",
    "        \"\"\"Compute collapsed log joint: log p(z, f | alpha, beta).\"\"\"\n",
    "\n",
    "        # Prior over z: Dirichlet-multinomial on class counts\n",
    "        log_prob: float = gammaln(self._n_classes * alpha) - gammaln(self._n_wordtypes + self._n_classes * alpha)\n",
    "        log_prob += (gammaln(self._x_class_counts + alpha) - gammaln(alpha)).sum()\n",
    "\n",
    "        # Likelihood: product over classes of Dirichlet-multinomial on feature counts\n",
    "        # left context\n",
    "        log_prob += (gammaln(self._n_features * beta_left) - gammaln(self._x_class_wordtype_counts_sum_left + self._n_features * beta_left)).sum()\n",
    "        log_prob += (gammaln(self._x_class_wordtype_counts_left + beta_left) - gammaln(beta_left)).sum()\n",
    "        # right context\n",
    "        log_prob += (gammaln(self._n_features * beta_right) - gammaln(self._x_class_wordtype_counts_sum_right + self._n_features * beta_right)).sum()\n",
    "        log_prob += (gammaln(self._x_class_wordtype_counts_right + beta_right) - gammaln(beta_right)).sum()\n",
    "\n",
    "        return log_prob\n",
    "        \n",
    "\n",
    "    def _remove_class_assignment(self, ix: int) -> int:\n",
    "        \"\"\"Remove word type class assignment.\"\"\"\n",
    "        assert isinstance(ix, (int, np.integer))\n",
    "        \n",
    "        # get word type class assignment\n",
    "        z: int = self._x_wordtype_class_assignments[ix]\n",
    "        \n",
    "        # decrement class count\n",
    "        self._x_class_counts[z] -= 1\n",
    "        \n",
    "        # decrement class word type counts\n",
    "        self._x_class_wordtype_counts_left[z] -= self._x_wordtype_counts_left[ix]\n",
    "        self._x_class_wordtype_counts_right[z] -= self._x_wordtype_counts_right[ix]\n",
    "        \n",
    "        # decrement from class totals\n",
    "        self._x_class_wordtype_counts_sum_left[z] -= self._x_wordtype_counts_sum_left[ix]\n",
    "        self._x_class_wordtype_counts_sum_right[z] -= self._x_wordtype_counts_sum_right[ix]\n",
    "\n",
    "        return z\n",
    "\n",
    "    def _add_class_assignment(self, ix: int, z: int) -> None:\n",
    "        \"\"\"Add word type class assignment.\"\"\"\n",
    "        assert isinstance(ix, (int, np.integer))\n",
    "        assert isinstance(z, (int, np.integer))\n",
    "        \n",
    "        # assign new class\n",
    "        self._x_wordtype_class_assignments[ix] = z\n",
    "        \n",
    "        # increment class count\n",
    "        self._x_class_counts[z] += 1\n",
    "        \n",
    "        # increment class word type counts\n",
    "        self._x_class_wordtype_counts_left[z] += self._x_wordtype_counts_left[ix]\n",
    "        self._x_class_wordtype_counts_right[z] += self._x_wordtype_counts_right[ix]\n",
    "        \n",
    "        # increment from class totals\n",
    "        self._x_class_wordtype_counts_sum_left[z] += self._x_wordtype_counts_sum_left[ix]\n",
    "        self._x_class_wordtype_counts_sum_right[z] += self._x_wordtype_counts_sum_right[ix]\n",
    "        \n",
    "    def _run_sweep(self, alpha: float, beta_left: float, beta_right: float) -> None:\n",
    "        \"\"\"Run Gibbs sweep.\"\"\"\n",
    "        # --- gibbs sweep\n",
    "        for ix_wordtype in np.random.permutation(self._n_wordtypes):\n",
    "    \n",
    "            # --- remove word type assignment\n",
    "            z_old: int = self._remove_class_assignment(ix=ix_wordtype)\n",
    "            \n",
    "            # --- recompute gibbs log conditional\n",
    "            class_probs: np.ndarray = self._compute_log_conditional_probability(ix=ix_wordtype, alpha=alpha, beta_left=beta_left, beta_right=beta_right)\n",
    "\n",
    "            # --- sample new assignment\n",
    "            z_new: int = np.random.choice(self._n_classes, p=class_probs)\n",
    "\n",
    "            # --- add word type assignment\n",
    "            _ = self._add_class_assignment(ix=ix_wordtype, z=z_new)\n",
    "\n",
    "    def compute_posterior_class_probs(self, samples, wordtype_index) -> np.ndarray:\n",
    "        \"\"\"Compute empirical posterior P(z_j = c | data) for one word type.\"\"\"\n",
    "        x_counts: np.ndarray = np.zeros(self._n_classes, dtype=float)\n",
    "        for z in samples:\n",
    "            x_counts[z[wordtype_index]] += 1\n",
    "        probs: np.ndarray = x_counts / x_counts.sum()\n",
    "        return probs\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_word_type_posterior_entropy(x_word_type_posterior_probs: np.ndarray, epsilon: float = 1e-12):\n",
    "        \"\"\"Compute word type posterior entropy.\"\"\"\n",
    "        x_word_type_posterior_probs_clipped = np.clip(x_word_type_posterior_probs, epsilon, 1.0)\n",
    "        return -(x_word_type_posterior_probs_clipped * np.log(x_word_type_posterior_probs_clipped)).sum(axis=1)\n",
    "\n",
    "    def run(self, n_iterations: int, alpha: float, beta_left: float, beta_right: float, n_burn_in: int, n_thinning: int) -> Tuple[List[float], List[np.ndarray], List[int], np.ndarray]:\n",
    "        \"\"\"Run Gibbs sampler.\"\"\"\n",
    "        assert isinstance(n_iterations, int)\n",
    "        assert n_iterations > 0\n",
    "        assert isinstance(alpha, float)\n",
    "        assert isinstance(beta_left, float)\n",
    "        assert isinstance(beta_right, float)\n",
    "\n",
    "        log_probs_trace, class_counts_trace, samples = [], [], []\n",
    "        # reset posterior accumulators\n",
    "        x_word_type_posterior_counts: np.ndarray = np.zeros((self._n_wordtypes, self._n_classes), dtype=int)\n",
    "        n_posterior_samples_kept: int = 0\n",
    "        \n",
    "        for ix_iteration in range(n_iterations):\n",
    "            _ = self._run_sweep(alpha=alpha, beta_left=beta_left, beta_right=beta_right)\n",
    "            log_prob: float = self._compute_log_joint_probability(alpha=alpha, beta_left=beta_left, beta_right=beta_right)\n",
    "\n",
    "            # trace\n",
    "            log_probs_trace.append(log_prob)\n",
    "            class_counts_trace.append(self._x_class_counts.copy())\n",
    "\n",
    "            # collect thinned samples after burn-in\n",
    "            if ix_iteration >= n_burn_in and ((ix_iteration - n_burn_in) % n_thinning == 0):\n",
    "                samples.append(self._x_wordtype_class_assignments.copy())\n",
    "                \n",
    "                # online posterior accumulation: increment (j, z_j)\n",
    "                x_word_type_posterior_counts[np.arange(self._n_wordtypes), self._x_wordtype_class_assignments] += 1\n",
    "                n_posterior_samples_kept += 1\n",
    "\n",
    "            # log\n",
    "            print(f'Iteration: {ix_iteration} log_prob: {log_prob}')\n",
    "\n",
    "        x_word_type_posterior_probs: np.ndarray = x_word_type_posterior_counts / float(n_posterior_samples_kept)\n",
    "\n",
    "        return log_probs_trace, class_counts_trace, samples, x_word_type_posterior_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae689f-0f97-4a0f-9287-da5f94524d5f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5310ab-4b40-44d1-ae4e-9887a60d096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_iterations = 300\n",
    "n_burn_in = 100\n",
    "n_thinning = 5\n",
    "alpha = .1\n",
    "beta_left, beta_right = .5, .5\n",
    "\n",
    "sampler = GibbsSampler(x_wordtype_counts_left=x_wordtype_counts_left, x_wordtype_counts_right=x_wordtype_counts_right, n_classes=n_classes)\n",
    "\n",
    "log_probs_trace, class_counts_trace, samples, x_word_type_posterior_probs = sampler.run(\n",
    "    n_iterations=n_iterations, alpha=alpha, beta_left=beta_left, beta_right=beta_right,\n",
    "    n_burn_in=n_burn_in, n_thinning=n_thinning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f101d-5b29-4e4f-a7b7-09ef3fe1b4fb",
   "metadata": {},
   "source": [
    "# Dump artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "423e05be-82b5-4185-a418-cbc4267f1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = f'outputs/train/alpha={alpha}_beta_left={beta_left}_beta_right={beta_right}'\n",
    "!mkdir -p {path_output}\n",
    "_ = joblib.dump(log_probs_trace, f'{path_output}/log_probs_trace.joblib')\n",
    "_ = joblib.dump(class_counts_trace, f'{path_output}/class_counts_trace.joblib')\n",
    "_ = joblib.dump(samples, f'{path_output}/samples.joblib')\n",
    "_ = joblib.dump(x_word_type_posterior_probs, f'{path_output}/x_word_type_posterior_probs.joblib')\n",
    "_ = joblib.dump(sampler, f'{path_output}/sampler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8be29-eb0b-474c-9f52-57e21a6704e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-bayesian_pos_tagger",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "bayesian_pos_tagger",
   "language": "python",
   "name": "conda-base-bayesian_pos_tagger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
