{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e114422-c300-4ca5-9452-eecd8e587b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import unicodedata\n",
    "from glob import glob\n",
    "\n",
    "def tokenize(text):\n",
    "    # text = clean(text.lower())\n",
    "    rx = re.compile(r\"\\b\\p{L}[\\p{L}\\p{M}\\p{N}'â€™-]*\\b\", re.UNICODE)\n",
    "    return rx.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb738bf-e85e-44b6-9351-39615daa1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for f in glob('../data/raw/*.txt'):\n",
    "    for l in open(f, 'r').readlines():\n",
    "        counter.update(tokenize(l))\n",
    "\n",
    "n_most_common_wordtypes = 100\n",
    "n_features = n_most_common_wordtypes + 2\n",
    "most_common_wordtypes = list(map(itemgetter(0), counter.most_common(n_most_common_wordtypes))) + ['<BOS>', '<EOS>']\n",
    "feature_to_ix = dict(zip(most_common_wordtypes, range(len(most_common_wordtypes))))\n",
    "wordtype_to_ix = dict(zip(counter.keys(), range(len(counter.keys()))))\n",
    "n_wordtypes = len(wordtype_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cc2dfd-8fd0-45e3-960b-4056dce93c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# extra dimension to count ignored words. to be removed later.\n",
    "x_wordtype_counts_left = np.zeros((n_wordtypes, n_features + 1)).astype(int)\n",
    "x_wordtype_counts_right = np.zeros((n_wordtypes, n_features + 1)).astype(int)\n",
    "\n",
    "for f in glob('../data/raw/*.txt'):\n",
    "    for l in open(f, 'r').readlines():\n",
    "        tokens = ['<BOS>'] + tokenize(l) + ['<EOS>']\n",
    "        for ix in range(1, len(tokens) - 1):\n",
    "            x_wordtype_counts_left[wordtype_to_ix[tokens[ix]], feature_to_ix.get(tokens[ix-1], -1)] += 1\n",
    "            x_wordtype_counts_right[wordtype_to_ix[tokens[ix]], feature_to_ix.get(tokens[ix+1], -1)] += 1\n",
    "            # print(words[ix-1], words[ix], words[ix+1])\n",
    "\n",
    "# remove ignored words\n",
    "x_wordtype_counts_left = x_wordtype_counts_left[:, :n_features]\n",
    "x_wordtype_counts_right = x_wordtype_counts_right[:, :n_features]\n",
    "\n",
    "x_wordtype_counts_sum_left = x_wordtype_counts_left.sum(axis=1)\n",
    "x_wordtype_counts_sum_right = x_wordtype_counts_right.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37e181c-f7c4-491f-8e2e-fb561cead3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), (108501,), (10,), (108501, 102), (108501, 102))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 10\n",
    "\n",
    "x_class_priors = np.array([1/z] * z) # shape: (M,)\n",
    "x_wordtype_class_assignments = np.random.choice(range(len(x_class_priors)), p=x_class_priors, size=n_wordtypes) # shape: (M,)\n",
    "x_class_counts = np.bincount(x_wordtype_class_assignments) # shape: (Z,)\n",
    "\n",
    "x_class_priors.shape, x_wordtype_class_assignments.shape, x_class_counts.shape, x_wordtype_counts_left.shape, x_wordtype_counts_right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4659a722-0897-4049-b824-4993cc67c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_class_wordtype_counts_left = np.zeros((z, n_features)).astype(int)\n",
    "x_class_wordtype_counts_right = np.zeros((z, n_features)).astype(int)\n",
    "np.add.at(x_class_wordtype_counts_left, x_wordtype_class_assignments, x_wordtype_counts_left)\n",
    "np.add.at(x_class_wordtype_counts_right, x_wordtype_class_assignments, x_wordtype_counts_right)\n",
    "x_class_wordtype_counts_sum_left = x_class_wordtype_counts_left.sum(axis=1)\n",
    "x_class_wordtype_counts_sum_right = x_class_wordtype_counts_right.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80f2718-fd8a-4795-8e38-9edcddddb450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammaln\n",
    "\n",
    "\n",
    "alpha = .5\n",
    "betas = np.array([.5, .5])\n",
    "n_iterations = 1\n",
    "\n",
    "for ix_iteration in range(n_iterations):\n",
    "    for ix_wordtype in range(n_wordtypes):\n",
    "    # for ix_wordtype in range(n_wordtypes)[:1]:\n",
    "\n",
    "        # --- remove word type assignment\n",
    "        # get word type class assignment\n",
    "        z_old = x_wordtype_class_assignments[ix_wordtype]\n",
    "        \n",
    "        # decrement class count\n",
    "        x_class_counts[z_old] -= 1\n",
    "        \n",
    "        # decrement class word type counts\n",
    "        x_class_wordtype_counts_left[z_old] -= x_wordtype_counts_left[ix_wordtype]\n",
    "        x_class_wordtype_counts_right[z_old] -= x_wordtype_counts_right[ix_wordtype]\n",
    "        # decrement from class totals\n",
    "        x_class_wordtype_counts_sum_left[z_old] -= x_wordtype_counts_sum_left[ix_wordtype]\n",
    "        x_class_wordtype_counts_sum_right[z_old] -= x_wordtype_counts_sum_right[ix_wordtype]\n",
    "\n",
    "        # --- recompute posterior\n",
    "        log_scores = np.log(x_class_counts + alpha) # drop denominator since its common to all classes.\n",
    "        # left context features\n",
    "        log_scores += (\n",
    "            (gammaln(x_class_wordtype_counts_left + x_wordtype_counts_left[ix_wordtype] + betas[0]) - gammaln(x_class_wordtype_counts_left + betas[0])).sum(axis=1)\n",
    "            - (gammaln(x_class_wordtype_counts_sum_left + x_wordtype_counts_sum_left[ix_wordtype] + n_features * betas[0]) - gammaln(x_class_wordtype_counts_sum_left + n_features * betas[0]))\n",
    "        )\n",
    "        # right context features\n",
    "        log_scores += (\n",
    "            (gammaln(x_class_wordtype_counts_right + x_wordtype_counts_right[ix_wordtype] + betas[0]) - gammaln(x_class_wordtype_counts_right + betas[0])).sum(axis=1)\n",
    "            - (gammaln(x_class_wordtype_counts_sum_right + x_wordtype_counts_sum_right[ix_wordtype] + n_features * betas[0]) - gammaln(x_class_wordtype_counts_sum_right + n_features * betas[0]))\n",
    "        )\n",
    "\n",
    "        # --- sample new assignment\n",
    "        z_new = _sample_from_log_probs(log_scores)\n",
    "        # increment class count\n",
    "        x_class_counts[z_new] += 1\n",
    "        # increment class word type counts\n",
    "        x_class_wordtype_counts_left[z_new] += x_wordtype_counts_left[ix_wordtype]\n",
    "        x_class_wordtype_counts_right[z_new] += x_wordtype_counts_right[ix_wordtype]\n",
    "        # increment from class totals\n",
    "        x_class_wordtype_counts_sum_left[z_new] += x_wordtype_counts_sum_left[ix_wordtype]\n",
    "        x_class_wordtype_counts_sum_right[z_new] += x_wordtype_counts_sum_right[ix_wordtype]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3aa0a8f-36ca-4225-b375-e2df16f19f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _sample_from_log_probs(logp):\n",
    "    \"\"\"Sample a categorical outcome from unnormalized log-probabilities.\"\"\"\n",
    "    m = np.max(logp)\n",
    "    p = np.exp(logp - m)\n",
    "    p /= p.sum()\n",
    "    return np.random.choice(len(logp), p=p)\n",
    "\n",
    "_sample_from_log_probs(log_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd575c2d-02e3-4b99-bfe3-1be52460f332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
